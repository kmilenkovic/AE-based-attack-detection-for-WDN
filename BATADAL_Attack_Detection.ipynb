{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets path\n",
    "data_path = 'data' # NOTE: Change this path to the location of your BATADAL dataset files\n",
    "\n",
    "# Load benign train data\n",
    "train_benign_data = pd.read_csv(os.path.join(data_path, 'BATADAL_dataset03.csv')) # clean data\n",
    "\n",
    "# Load attack train data\n",
    "train_attack_data = pd.read_csv(os.path.join(data_path, 'BATADAL_dataset04.csv')) # data with attacks: 6-months long; attacks 1-7\n",
    "train_attack_data = train_attack_data.rename(\n",
    "                                columns={' L_T1': 'L_T1', ' L_T2': 'L_T2', ' L_T3': 'L_T3', ' L_T4': 'L_T4', ' L_T5': 'L_T5', ' L_T6': 'L_T6',\t' L_T7': 'L_T7',\n",
    "                                            ' P_J14': 'P_J14', ' P_J422': 'P_J422', ' P_J280': 'P_J280', ' P_J269': 'P_J269', ' P_J300': 'P_J300', ' P_J256': 'P_J256', ' P_J289': 'P_J289', ' P_J415': 'P_J415', ' P_J302': 'P_J302', ' P_J306': 'P_J306', ' P_J307': 'P_J307', ' P_J317': 'P_J317',\n",
    "                                            ' F_PU1': 'F_PU1', ' F_PU2': 'F_PU2', ' F_PU3': 'F_PU3', ' F_PU4': 'F_PU4', ' F_PU5': 'F_PU5', ' F_PU6': 'F_PU6', ' F_PU7': 'F_PU7', ' F_PU8': 'F_PU8', ' F_PU9': 'F_PU9', ' F_PU10': 'F_PU10', ' F_PU11': 'F_PU11', ' F_V2': 'F_V2',\n",
    "                                            ' S_PU1': 'S_PU1', ' S_PU2': 'S_PU2', ' S_PU3': 'S_PU3', ' S_PU4': 'S_PU4', ' S_PU5': 'S_PU5', ' S_PU6': 'S_PU6', ' S_PU7': 'S_PU7', ' S_PU8': 'S_PU8', ' S_PU9': 'S_PU9', ' S_PU10': 'S_PU10', ' S_PU11': 'S_PU11', ' S_V2': 'S_V2'})\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv(os.path.join(data_path, 'BATADAL_test_dataset.csv')) # data with attacks: 3-months long; attacks 8-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the DATETIME column and the features\n",
    "train_benign_datetime = train_benign_data['DATETIME']\n",
    "train_attack_datetime = train_attack_data['DATETIME']\n",
    "test_datetime = test_data['DATETIME']\n",
    "\n",
    "# Preprocessing: Scale data using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train_benign_scaled = scaler.fit_transform(train_benign_data.drop(columns=['DATETIME', 'ATT_FLAG']))\n",
    "train_attack_scaled = scaler.transform(train_attack_data.drop(columns=['DATETIME', ' ATT_FLAG']))\n",
    "test_scaled = scaler.transform(test_data.drop(columns=['DATETIME']))\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_benign_tensor = torch.tensor(train_benign_scaled, dtype=torch.float32)\n",
    "train_attack_tensor = torch.tensor(train_attack_scaled, dtype=torch.float32)\n",
    "test_tensor = torch.tensor(test_scaled, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack intervals\n",
    "train_benign_attacks_time_intervals = []\n",
    "train_attack_attacks_time_intervals = [\n",
    "        {\"id\": 1, \"start\": \"13/09/2016 23\", \"end\": \"16/09/2016 00\"},    # Attacker changesL_T7 thresholds -->> low level in T7\n",
    "        {\"id\": 2, \"start\": \"26/09/2016 11\", \"end\": \"27/09/2016 10\"},    # Attacker changesL_T7 thresholds -->> T2 low level in T7\n",
    "        {\"id\": 3, \"start\": \"09/10/2016 09\", \"end\": \"11/10/2016 20\"},   # Attack alters L_T1 readings -->> pumps PU1/PU2 on stays on\n",
    "        {\"id\": 4, \"start\": \"29/10/2016 19\", \"end\": \"02/11/2016 16\"},   # Attack alters L_T1 readings -->> pumps PU1/PU2 on stays on\n",
    "        {\"id\": 5, \"start\": \"26/11/2016 17\", \"end\": \"29/11/2016 04\"},   # Attacker reduces working speed of PU7 -->> lower water levels in T4\n",
    "        {\"id\": 6, \"start\": \"06/12/2016 07\", \"end\": \"10/12/2016 04\"},   # Attacker reduces working speed of PU7 -->> lower water levels in T4\n",
    "        {\"id\": 7, \"start\": \"14/12/2016 15\", \"end\": \"19/12/2016 04\"},    # Attacker reduces working speed of PU7 -->> lower water levels in T4\n",
    "]\n",
    "test_attacks_time_intervals = [\n",
    "        {\"id\": 8, \"start\": \"16/01/2017 00\", \"end\": \"19/01/2017 06\"},    # Attacker changes L_T3 thresholds -->> low level in T3\n",
    "        {\"id\": 9, \"start\": \"30/01/2017 08\", \"end\": \"02/02/2017 00\"},    # Attacker changes L_T2 readings -->> T2 overflow\n",
    "        {\"id\": 10, \"start\": \"09/02/2017 03\", \"end\": \"10/02/2017 09\"},   # Malicious activation of pump PU3\n",
    "        {\"id\": 11, \"start\": \"12/02/2017 01\", \"end\": \"13/02/2017 07\"},   # Malicious activation of pump PU3\n",
    "        {\"id\": 12, \"start\": \"24/02/2017 05\", \"end\": \"28/02/2017 08\"},   # Attacker changes L_T2, F_V2 and S_V2, P_J14 and P_J422 -->> T2 overflow\n",
    "        {\"id\": 13, \"start\": \"10/03/2017 14\", \"end\": \"13/03/2017 21\"},   # Attacker changes L_T7 thresholds -->> PU10/PU11 are switching on/off continuously\n",
    "        {\"id\": 14, \"start\": \"25/03/2017 20\", \"end\": \"27/03/2017 01\"}    # Attacker changes L_T4 readings -->> T6 overflow\n",
    "]\n",
    "\n",
    "# Convert attack intervals to datetime objects\n",
    "train_benign_attacks_intervals = [\n",
    "    {\n",
    "        \"id\": interval[\"id\"],\n",
    "        \"start\": pd.to_datetime(interval[\"start\"], format=\"%d/%m/%Y %H\"),\n",
    "        \"end\": pd.to_datetime(interval[\"end\"], format=\"%d/%m/%Y %H\")\n",
    "    }\n",
    "    for interval in train_benign_attacks_time_intervals\n",
    "]\n",
    "train_attack_attacks_intervals = [\n",
    "    {\n",
    "        \"id\": interval[\"id\"],\n",
    "        \"start\": pd.to_datetime(interval[\"start\"], format=\"%d/%m/%Y %H\"),\n",
    "        \"end\": pd.to_datetime(interval[\"end\"], format=\"%d/%m/%Y %H\")\n",
    "    }\n",
    "    for interval in train_attack_attacks_time_intervals\n",
    "]\n",
    "test_attacks_intervals = [\n",
    "    {\n",
    "        \"id\": interval[\"id\"],\n",
    "        \"start\": pd.to_datetime(interval[\"start\"], format=\"%d/%m/%Y %H\"),\n",
    "        \"end\": pd.to_datetime(interval[\"end\"], format=\"%d/%m/%Y %H\")\n",
    "    }\n",
    "    for interval in test_attacks_time_intervals\n",
    "]\n",
    "\n",
    "# Attack indexes\n",
    "train_benign_attacks_index_intervals = []\n",
    "train_attack_attacks_index_intervals = [\n",
    "        {\"id\": 1, \"start\": 1727, \"end\": 1776},    # Attacker changesL_T7 thresholds -->> low level in T7\n",
    "        {\"id\": 2, \"start\": 2027, \"end\": 2050},    # Attacker changesL_T7 thresholds -->> T2 low level in T7\n",
    "        {\"id\": 3, \"start\": 2337, \"end\": 2396},    # Attack alters L_T1 readings -->> pumps PU1/PU2 on stays on\n",
    "        {\"id\": 4, \"start\": 2827, \"end\": 2920},    # Attack alters L_T1 readings -->> pumps PU1/PU2 on stays on\n",
    "        {\"id\": 5, \"start\": 3497, \"end\": 3556},    # Attacker reduces working speed of PU7 -->> lower water levels in T4\n",
    "        {\"id\": 6, \"start\": 3727, \"end\": 3820},    # Attacker reduces working speed of PU7 -->> lower water levels in T4\n",
    "        {\"id\": 7, \"start\": 3927, \"end\": 4036},    # Attacker reduces working speed of PU7 -->> lower water levels in T4\n",
    "]\n",
    "test_attacks_index_intervals = [\n",
    "        {\"id\": 8, \"start\": 297, \"end\": 366},    # Attacker changes L_T3 thresholds -->> low level in T3\n",
    "        {\"id\": 9, \"start\": 632, \"end\": 696},    # Attacker changes L_T2 readings -->> T2 overflow\n",
    "        {\"id\": 10, \"start\": 867, \"end\": 897},   # Malicious activation of pump PU3\n",
    "        {\"id\": 11, \"start\": 937, \"end\": 967},   # Malicious activation of pump PU3\n",
    "        {\"id\": 12, \"start\": 1229, \"end\": 1328},   # Attacker changes L_T2, F_V2 and S_V2, P_J14 and P_J422 -->> T2 overflow\n",
    "        {\"id\": 13, \"start\": 1574, \"end\": 1653},   # Attacker changes L_T7 thresholds -->> PU10/PU11 are switching on/off continuously\n",
    "        {\"id\": 14, \"start\": 1940, \"end\": 1969}    # Attacker changes L_T4 readings -->> T6 overflow\n",
    "]\n",
    "\n",
    "train_benign_attacks_indices  = np.zeros(train_benign_tensor.shape[0])\n",
    "for attack in train_benign_attacks_index_intervals:\n",
    "    train_benign_attacks_indices[attack['start']:attack['end']+1] = 1\n",
    "train_attack_attacks_indices  = np.zeros(train_attack_tensor.shape[0])\n",
    "for attack in train_attack_attacks_index_intervals:\n",
    "    train_attack_attacks_indices[attack['start']:attack['end']+1] = 1\n",
    "test_attacks_indices  = np.zeros(test_tensor.shape[0])\n",
    "for attack in test_attacks_index_intervals:\n",
    "    test_attacks_indices[attack['start']:attack['end']+1] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column to indicate if the network is attacked or not\n",
    "\n",
    "# Training data - benign\n",
    "new_column = torch.zeros(train_benign_tensor.shape[0], 1)  # Create a column of zeros and ones with the same number of rows\n",
    "for attack in train_benign_attacks_index_intervals:\n",
    "    new_column[attack[\"start\"]:attack[\"end\"]+1] = 0\n",
    "train_benign_tensor = torch.cat((train_benign_tensor, new_column), dim=1) # Concatenate along the column dimension (dim=1)\n",
    "\n",
    "# Training data - attack\n",
    "new_column = torch.zeros(train_attack_tensor.shape[0], 1)  # Create a column of zeros and ones with the same number of rows\n",
    "for attack in train_attack_attacks_index_intervals:\n",
    "    new_column[attack[\"start\"]:attack[\"end\"]+1] = 1\n",
    "train_attack_tensor = torch.cat((train_attack_tensor, new_column), dim=1) # Concatenate along the column dimension (dim=1)\n",
    "\n",
    "# Testing data\n",
    "new_column = torch.zeros(test_tensor.shape[0], 1)  # Create a column of zeros and ones with the same number of rows\n",
    "for attack in test_attacks_index_intervals:\n",
    "    new_column[attack[\"start\"]:attack[\"end\"]+1] = 1\n",
    "test_tensor = torch.cat((test_tensor, new_column), dim=1) # Concatenate along the column dimension (dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class for Time Series Windowing\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, window_size):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.window_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[idx:idx + self.window_size], self.data[idx + self.window_size])\n",
    "\n",
    "\n",
    "# Parameters\n",
    "window_sizes = [1,2,8,16,32]\n",
    "batch_size = 64\n",
    "\n",
    "# Create datasets and data loaders\n",
    "train_benign_dataset = []\n",
    "train_attack_dataset = []\n",
    "test_dataset = []\n",
    "train_benign_loader = []\n",
    "train_attack_loader = []\n",
    "test_loader = []\n",
    "for idx, window_size in enumerate(window_sizes):\n",
    "  # Create datasets\n",
    "  train_benign_dataset.append(TimeSeriesDataset(train_benign_tensor, window_size))\n",
    "  train_attack_dataset.append(TimeSeriesDataset(train_attack_tensor, window_size))\n",
    "  test_dataset.append(TimeSeriesDataset(test_tensor, window_size))\n",
    "\n",
    "  # Create data loaders\n",
    "  train_benign_loader.append(DataLoader(train_benign_dataset[idx], batch_size=batch_size, shuffle=True))\n",
    "  train_attack_loader.append(DataLoader(train_attack_dataset[idx], batch_size=batch_size, shuffle=True))\n",
    "  test_loader.append(DataLoader(test_dataset[idx], batch_size=1, shuffle=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_benign_scaled.shape[1]\n",
    "\n",
    "print(\"Number of features: \", input_dim)\n",
    "print(f\"Benign train data shape: {train_benign_tensor.shape}\")\n",
    "print(f\"Attack aware train data shape: {train_attack_tensor.shape}\")\n",
    "print(f\"Test data shape: {test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "###################### Transformer-based Autoencoder #######################\n",
    "# Define Transformer-based Autoencoder\n",
    "class TransformerAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, ff_dim, num_layers):\n",
    "        super(TransformerAutoencoder, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim, batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        self.output_layer = nn.Linear(embed_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        encoded = self.encoder(embedded)\n",
    "        decoded = self.decoder(encoded, embedded)\n",
    "        output = self.output_layer(decoded)\n",
    "        return output\n",
    "\n",
    "###################### Convolutional Recurrent Autoencoder #######################\n",
    "# Define Convolutional Recurrent Autoencoder\n",
    "class ConvRecurrentAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers):\n",
    "        super(ConvRecurrentAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder: Convolutional Layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=hidden_dim, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Encoder: GRU Layers\n",
    "        self.gru_encoder = nn.GRU(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Decoder: GRU Layers\n",
    "        self.gru_decoder = nn.GRU(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Decoder: Deconvolutional Layers\n",
    "        self.deconv1 = nn.ConvTranspose1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.deconv2 = nn.ConvTranspose1d(in_channels=hidden_dim, out_channels=input_dim, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder: Convolutional Layers\n",
    "        # Input shape: (batch_size, sequence_length, input_dim)\n",
    "        x = x.permute(0, 2, 1)  # Switch to (batch_size, input_dim, sequence_length) for Conv1d\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "\n",
    "        # Encoder: GRU Layers\n",
    "        # Input shape after conv: (batch_size, hidden_dim, sequence_length)\n",
    "        x = x.permute(0, 2, 1)  # Switch to (batch_size, sequence_length, hidden_dim) for GRU\n",
    "        _, h = self.gru_encoder(x)\n",
    "\n",
    "        # Decoder: GRU Layers\n",
    "        decoded, _ = self.gru_decoder(x, h)\n",
    "\n",
    "        # Decoder: Deconvolutional Layers\n",
    "        # Output shape after GRU: (batch_size, sequence_length, hidden_dim)\n",
    "        decoded = decoded.permute(0, 2, 1)  # Switch to (batch_size, hidden_dim, sequence_length) for ConvTranspose1d\n",
    "        decoded = self.relu(self.deconv1(decoded))\n",
    "        output = self.deconv2(decoded)\n",
    "\n",
    "        return output.permute(0, 2, 1)  # Return to (batch_size, sequence_length, input_dim)\n",
    "\n",
    "####################### Fully Connected Autoencoder #######################\n",
    "# Define Fully Connected Autoencoder based on the paper\n",
    "class FullyConnectedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, num_layers):\n",
    "        super(FullyConnectedAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder: Fully Connected Layers with Tanh activations\n",
    "        encoder_layers = []\n",
    "        current_dim = input_dim\n",
    "        for _ in range(num_layers - 1):\n",
    "            encoder_layers.append(nn.Linear(current_dim, hidden_dim))\n",
    "            encoder_layers.append(nn.Tanh())\n",
    "            current_dim = hidden_dim\n",
    "        # Final layer to latent space\n",
    "        encoder_layers.append(nn.Linear(current_dim, latent_dim))\n",
    "        encoder_layers.append(nn.Tanh())\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "\n",
    "        # Decoder: Fully Connected Layers with Tanh activations\n",
    "        decoder_layers = []\n",
    "        current_dim = latent_dim\n",
    "        for _ in range(num_layers - 1):\n",
    "            decoder_layers.append(nn.Linear(current_dim, hidden_dim))\n",
    "            decoder_layers.append(nn.Tanh())\n",
    "            current_dim = hidden_dim\n",
    "        # Final layer to reconstruct the input\n",
    "        decoder_layers.append(nn.Linear(current_dim, input_dim))\n",
    "        decoder_layers.append(nn.Tanh())  # Assuming input data is scaled between -1 and 1\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input if necessary (assuming input shape is (batch_size, sequence_length, input_dim))\n",
    "        batch_size, sequence_length, input_dim = x.shape\n",
    "        x = x.view(batch_size * sequence_length, input_dim)  # Flatten input to (batch_size * sequence_length, input_dim)\n",
    "\n",
    "        # Encoder\n",
    "        encoded = self.encoder(x)\n",
    "\n",
    "        # Decoder\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        # Reshape the output back to the original format (batch_size, sequence_length, input_dim)\n",
    "        output = decoded.view(batch_size, sequence_length, input_dim)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight the Loss Function\n",
    "Use a weighted loss function to penalize reconstruction errors differently for normal and anomalous data:\n",
    "\n",
    "*   Assign a higher weight to reconstruction errors for normal data, encouraging the model to focus on learning the normal pattern.\n",
    "*   Assign a lower weight to reconstruction errors for anomalous data, preventing the autoencoder from learning to reconstruct anomalies effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute loss\n",
    "from torch import nn\n",
    "\n",
    "def custom_loss(outputs, inputs, normal_weight=1, anomaly_weight=1):\n",
    "    if anomaly_weight==None:\n",
    "        loss_f = nn.MSELoss()\n",
    "        return loss_f(outputs, inputs[:,:, :-1])\n",
    "    else:\n",
    "        is_anomaly = inputs[:, :, -1]  # the last dimension indicates if it's an anomaly\n",
    "\n",
    "        is_not_anomaly_view = (1 - is_anomaly).view(-1)\n",
    "        is_not_anomaly_view = is_not_anomaly_view[:,None]\n",
    "\n",
    "        is_anomaly_view = is_anomaly.view(-1)\n",
    "        is_anomaly_view = is_anomaly_view[:,None]\n",
    "\n",
    "        mse_view = ((inputs[:,:, :-1] - outputs)**2).view(-1, 43)\n",
    "\n",
    "        loss_normal = normal_weight * (is_not_anomaly_view * mse_view).mean()\n",
    "        loss_anomaly = anomaly_weight * (is_anomaly_view * mse_view).mean()\n",
    "\n",
    "        return loss_normal + loss_anomaly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth the reconstruction error\n",
    "\n",
    "Postprocessing: an additional step - smoothing of anomaly scores (sliding averages) before the attack detection. The smoothing is performed by forming  of the anomaly score values preceding in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_sizes = [1,3,5,7,9,11,13,15,17,19,21,23,25,27,29]\n",
    "\n",
    "def smooth_models_reconstruction_errors(reconstruction_errors):\n",
    "  reconstruction_errors_for_filter_size = {}\n",
    "\n",
    "  for filter_size in filter_sizes:\n",
    "    reconstruction_errors_for_filter_size[filter_size] = []\n",
    "\n",
    "    l = len(reconstruction_errors)\n",
    "    for idx in range(l):\n",
    "      sublst = reconstruction_errors[max((idx-filter_size+1),0): min((idx+1), l)]\n",
    "      avg_val = sum(sublst) / len(sublst)\n",
    "\n",
    "      reconstruction_errors_for_filter_size[filter_size].append(avg_val)\n",
    "\n",
    "  return reconstruction_errors_for_filter_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import json\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "# NOTE: for anomaly_weight=None we have benign model\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs, anomaly_weight, device, print_progress=True):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = None\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs, _ = batch\n",
    "            inputs = inputs.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs[:,:,:-1])\n",
    "            loss = criterion(outputs, inputs, anomaly_weight=anomaly_weight)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        if print_progress:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss / len(train_loader):.6f}')\n",
    "\n",
    "    return model, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating loop\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    loss_f = nn.MSELoss()\n",
    "    \n",
    "    reconstruction_errors = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs, _ = batch\n",
    "            inputs = inputs.float().to(device)  # Ensure inputs are of the correct type (float32)\n",
    "            outputs = model(inputs[:,:,:-1])   # Get model output\n",
    "            loss = loss_f(outputs, inputs[:,:, :-1]).item()  # Calculate MSE for the batch\n",
    "            reconstruction_errors.append(loss)\n",
    "\n",
    "    return reconstruction_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation loop\n",
    "# for anomaly_weight=None we have benign model\n",
    "def train_and_evaluate(model, train_loader, test_loader, optimizer, epochs, anomaly_weight, device):\n",
    "    criterion = custom_loss\n",
    "\n",
    "    # Training loop\n",
    "    model, total_loss = train_model(model, train_loader, criterion, optimizer, epochs, anomaly_weight, device, print_progress=False)\n",
    "\n",
    "    # Evaluation loop\n",
    "    reconstruction_errors = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    # Return total loss and average validation loss\n",
    "    return model, total_loss, sum(reconstruction_errors) / len(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation and save loop\n",
    "# for anomaly_weight=None we have benign model\n",
    "def train_and_evaluate_and_save(model, models_path, model_name, train_loader, test_loader, optimizer, epochs, anomaly_weight, device):\n",
    "    criterion = custom_loss\n",
    "\n",
    "    # Training \n",
    "    model, _ = train_model(model, train_loader, criterion, optimizer, epochs, anomaly_weight, device, print_progress=False)\n",
    "\n",
    "    # Evaluation\n",
    "    reconstruction_errors = evaluate_model(model, test_loader, device)\n",
    "    smooth_reconstruction_errors = smooth_models_reconstruction_errors(reconstruction_errors)\n",
    "\n",
    "    # Save\n",
    "    torch.save(model, models_path + f'{model_name}.pth')\n",
    "    print(f'{model_name}.pth model saved')\n",
    "    with open(models_path + f\"reconstruction_errors_{model_name}.json\", \"w\") as file:\n",
    "      json.dump(reconstruction_errors, file)\n",
    "      print(f\"reconstruction errors saved to reconstruction_errors_{model_name}.json\")\n",
    "    with open(models_path + f\"smooth_reconstruction_errors_{model_name}.json\", \"w\") as file:\n",
    "      json.dump(smooth_reconstruction_errors, file)\n",
    "      print(f\"smooth reconstruction errors saved to smooth_reconstruction_errors_{model_name}.json\")\n",
    "\n",
    "    # Return\n",
    "    return model, reconstruction_errors, smooth_reconstruction_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_all(models_path, models_type, best_params, anomaly_weight, train_loader, test_loader, window_size, input_dim, device):\n",
    "\n",
    "  best_models = {}\n",
    "  reconstruction_errors = {}\n",
    "  smooth_reconstruction_errors = {}\n",
    "  \n",
    "  # Train models with best parameters\n",
    "  best_models['TransformerAutoencoder'] = TransformerAutoencoder(\n",
    "        input_dim=input_dim, \n",
    "        embed_dim=best_params['TransformerAutoencoder']['embed_dim'], \n",
    "        num_heads=best_params['TransformerAutoencoder']['num_heads'], \n",
    "        ff_dim=best_params['TransformerAutoencoder']['ff_dim'], \n",
    "        num_layers=best_params['TransformerAutoencoder']['num_layers']\n",
    "  ).to(device)\n",
    "  best_models['ConvRecurrentAutoencoder'] = ConvRecurrentAutoencoder(\n",
    "      input_dim=input_dim,\n",
    "      hidden_dim=best_params['ConvRecurrentAutoencoder']['hidden_dim'], \n",
    "      kernel_size=best_params['ConvRecurrentAutoencoder']['kernel_size'],\n",
    "      num_layers=best_params['ConvRecurrentAutoencoder']['num_layers']\n",
    "  ).to(device)\n",
    "  best_models['FullyConnectedAutoencoder'] = FullyConnectedAutoencoder(\n",
    "      input_dim=input_dim,\n",
    "      hidden_dim=best_params['FullyConnectedAutoencoder']['hidden_dim'],\n",
    "      latent_dim=best_params['FullyConnectedAutoencoder']['latent_dim'],\n",
    "      num_layers=best_params['FullyConnectedAutoencoder']['num_layers']\n",
    "    ).to(device)\n",
    "\n",
    "  for ae_type in ['TransformerAutoencoder', 'ConvRecurrentAutoencoder', 'FullyConnectedAutoencoder']:\n",
    "    print(f\"\\n#####   {ae_type}   #####\")\n",
    "\n",
    "    best_models[ae_type], reconstruction_errors[ae_type], smooth_reconstruction_errors[ae_type] = train_and_evaluate_and_save(\n",
    "      model = best_models[ae_type], \n",
    "      models_path = models_path, \n",
    "      model_name = f\"{models_type}_{ae_type}_ws{window_size}\", \n",
    "      train_loader = train_loader, \n",
    "      test_loader = test_loader, \n",
    "      optimizer = Adam(best_models[ae_type].parameters(), lr=best_params[ae_type]['learning_rate']),\n",
    "      epochs = best_params[ae_type]['epochs'], \n",
    "      anomaly_weight = anomaly_weight[ae_type],\n",
    "      device = device)\n",
    "    \n",
    "    print(f\"#####   END {ae_type}   #####\")\n",
    "\n",
    "  return best_models, reconstruction_errors, smooth_reconstruction_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_segments(arr):\n",
    "  \"\"\"\n",
    "  Finds segments of consecutive True values in a boolean array.\n",
    "\n",
    "  Args:\n",
    "    arr: A boolean NumPy array.\n",
    "\n",
    "  Returns:\n",
    "    A list of tuples, where each tuple represents a segment and contains the\n",
    "    start and end indices (inclusive) of the segment.\n",
    "  \"\"\"\n",
    "  segments = []\n",
    "  start = -1\n",
    "  for i in range(len(arr)):\n",
    "    if arr[i] and start == -1:\n",
    "      start = i\n",
    "    elif not arr[i] and start != -1:\n",
    "      segments.append((start, i - 1, i - start))\n",
    "      start = -1\n",
    "  if start != -1:\n",
    "    segments.append((start, len(arr) - 1, len(arr)))\n",
    "  return segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_performance(test_ground_truth_labels, reconstruction_errors, method_name):\n",
    "\n",
    "  # Calculate the best threshold to detect attacks using F1 score\n",
    "  precision, recall, thresholds = precision_recall_curve(test_ground_truth_labels, reconstruction_errors)\n",
    "\n",
    "  # Compute ROC curve\n",
    "  fpr, tpr, _ = roc_curve(test_ground_truth_labels, reconstruction_errors)\n",
    "  # Compute AUC (Area Under Curve)\n",
    "  roc_auc = auc(fpr, tpr)\n",
    "\n",
    "  # Calculate F1 score for each threshold\n",
    "  f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "  best_threshold_idx = np.argmax(f1_scores)\n",
    "  best_threshold = thresholds[best_threshold_idx]\n",
    "  best_f1_score = f1_scores[best_threshold_idx]\n",
    "\n",
    "  # Detect attacks using the best threshold\n",
    "  detected_attacks = reconstruction_errors > best_threshold\n",
    "\n",
    "  # TP\n",
    "  TP = np.sum((detected_attacks == 1) & (test_ground_truth_labels == 1))\n",
    "  # TN\n",
    "  TN = np.sum((detected_attacks == 0) & (test_ground_truth_labels == 0))\n",
    "  # FP\n",
    "  FP = np.sum((detected_attacks == 1) & (test_ground_truth_labels == 0))\n",
    "  # FN\n",
    "  FN = np.sum((detected_attacks == 0) & (test_ground_truth_labels == 1))\n",
    "\n",
    "  # TPR\n",
    "  TPR = TP/(TP+FN)\n",
    "  # TNR\n",
    "  TNR = TN/(FP+TN)\n",
    "\n",
    "  # Sclf\n",
    "  Sclf = (TPR + TNR)/2\n",
    "  # Sttd\n",
    "  Sttd = None\n",
    "\n",
    "  # Calculate the percentage of missed attack samples (False Negatives)\n",
    "  total_attack_samples = np.sum(test_ground_truth_labels == 1)\n",
    "  missed_attacks = np.sum((detected_attacks == 0) & (test_ground_truth_labels == 1))\n",
    "  missed_attack_percentage = (missed_attacks / total_attack_samples) * 100\n",
    "\n",
    "  # Calculate the percentage of wrongly detected samples (False Positives)\n",
    "  total_clean_samples = np.sum(test_ground_truth_labels == 0)\n",
    "  wrongly_detected = np.sum((detected_attacks == 1) & (test_ground_truth_labels == 0))\n",
    "  wrongly_detected_percentage = (wrongly_detected / total_clean_samples) * 100\n",
    "\n",
    "\n",
    "  # Add results to the table\n",
    "  new_row = {\n",
    "    \"num_of_detected\": 1,\n",
    "    \"TP\": TP,\n",
    "    \"FP\": FP,\n",
    "    \"TN\": TN,\n",
    "    \"FN\": FN,\n",
    "    \"TPR\": TPR,\n",
    "    \"TNR\": TNR,\n",
    "    \"S\": None, #y*Sttd+(1-y)*Sclf\n",
    "    \"Sttd\": Sttd,\n",
    "    \"Sclf\": Sclf,\n",
    "    \"total_attacks\": total_attack_samples,\n",
    "    \"total_clean\": total_clean_samples,\n",
    "    \"missed_attacks\": missed_attack_percentage,\n",
    "    \"wrongly_detected\": wrongly_detected_percentage,\n",
    "    \"accuracy\": (TP+TN)/(TP+TN+FP+FN),\n",
    "    \"f1_scores\": f1_scores,\n",
    "    \"best_f1_score\": best_f1_score,\n",
    "    \"best_threshold\": best_threshold,\n",
    "    \"precisuons\": precision,\n",
    "    \"recalls\": recall,\n",
    "    \"fpr\": fpr,\n",
    "    \"tpr\": tpr,\n",
    "    \"roc_auc\": roc_auc,\n",
    "  }\n",
    "  new_row_df = pd.DataFrame([new_row], index=[method_name])\n",
    "\n",
    "  return new_row_df, detected_attacks, precision, recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_reconstruction_errors(attack_indices, attack_index_intervals, window_size, reconstruction_errors, sufix=\"\", plot_threshold=False, threshold=None):\n",
    "    # Plotting both reconstruction errors on a single plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Adjust indices to account for the window size - First-Point Strategy\n",
    "    adjusted_indices = attack_indices[:-window_size]\n",
    "\n",
    "    for (errors, label, color) in reconstruction_errors:\n",
    "        plt.plot(adjusted_indices, errors, label=label, color=color)\n",
    "\n",
    "    # Shading attack intervals\n",
    "    for interval in attack_index_intervals:\n",
    "        start_idx = interval[\"start\"]\n",
    "        end_idx = interval[\"end\"]\n",
    "\n",
    "        # Adjust the indices to account for the window size\n",
    "        if start_idx >= window_size and end_idx >= window_size:\n",
    "            adjusted_start_idx = start_idx - window_size\n",
    "            adjusted_end_idx = end_idx - window_size\n",
    "            plt.axvspan(adjusted_start_idx, adjusted_end_idx, color='red', alpha=0.3)\n",
    "        elif start_idx < window_size and end_idx >= window_size:\n",
    "            adjusted_start_idx = 0\n",
    "            adjusted_end_idx = end_idx - window_size\n",
    "            plt.axvspan(adjusted_start_idx, adjusted_end_idx, color='red', alpha=0.3)\n",
    "\n",
    "    # Plot threshold\n",
    "    if plot_threshold:\n",
    "      plt.axhline(y=threshold, color='red', linestyle='--', label=\"Threshold\")\n",
    "\n",
    "    # Add labels, legend, and title\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.ylabel('Reconstruction Error')\n",
    "    plt.legend()\n",
    "    plt.title(f\"Reconstruction Error Over Time{sufix}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Parameters - Benign Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransformerAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_params = {}\n",
    "best_loss = {}\n",
    "best_error_params = {}\n",
    "best_error = {}\n",
    "for window_size in window_sizes:\n",
    "    best_loss_params[window_size] = None\n",
    "    best_loss[window_size] = float('inf')\n",
    "    best_error_params[window_size] = None\n",
    "    best_error[window_size] = float('inf')\n",
    "\n",
    "param_grid = {\n",
    "    'window_size': window_sizes,         # Window sizes to test\n",
    "    'embed_dim': [32, 64, 128, 256],     # Embedding dimension\n",
    "    'num_heads': [2, 4, 8, 16],          # Number of heads\n",
    "    'ff_dim': [128, 256, 512],           # Feedforward dimension\n",
    "    'num_layers': [1, 2, 4, 6],          # Number of GRU layers\n",
    "    'learning_rate': [1e-3, 1e-4, 1e-5], # Learning rates\n",
    "    'epochs': [30],                         # Number of epochs (fixed for quick testing)\n",
    "}\n",
    "\n",
    "print(f\"#\"*(len('TransformerAutoencoder')+16))\n",
    "print(f\"###     TransformerAutoencoder     ###\")\n",
    "print(f\"#\"*(len('TransformerAutoencoder')+16))\n",
    "\n",
    "for params in ParameterGrid(param_grid):     \n",
    "    print(f\"\\tTesting parameters: {params}\")\n",
    "        \n",
    "    # Initialize the model with current parameters\n",
    "    model = TransformerAutoencoder(\n",
    "        input_dim=input_dim,\n",
    "        embed_dim=params['embed_dim'],\n",
    "        num_heads=params['num_heads'],\n",
    "        ff_dim=params['ff_dim'],\n",
    "        num_layers=params['num_layers']\n",
    "    ).to(device)\n",
    "    \n",
    "    model, total_loss, avg_rec_error = train_and_evaluate(model=model, \n",
    "                                                          train_loader=train_benign_loader[window_sizes.index(params['window_size'])], \n",
    "                                                          test_loader=test_loader[window_sizes.index(params['window_size'])], \n",
    "                                                          optimizer=Adam(model.parameters(), lr=params['learning_rate']),\n",
    "                                                          epochs=params['epochs'], \n",
    "                                                          anomaly_weight=None, \n",
    "                                                          device=device)\n",
    "    print(f\"\\tTotal Loss: {total_loss}, Average Reconstruction Error: {avg_rec_error}\")\n",
    "\n",
    "    if total_loss < best_loss[params['window_size']]:\n",
    "        best_loss[params['window_size']] = total_loss\n",
    "        best_loss_params[params['window_size']] = params\n",
    "\n",
    "    if avg_rec_error < best_error[params['window_size']]:\n",
    "        best_error[params['window_size']] = avg_rec_error\n",
    "        best_error_params[params['window_size']] = params\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    print(f\"For Window Size = {window_size}:\")\n",
    "    print(f\"   TOTAL LOSS -- Best Parameters: {best_loss_params[window_size]}, Best Total Loss: {best_loss[window_size]}\")\n",
    "    print(f\"   AVERAGE RECONSTRUCTION ERROR -- Best Parameters: {best_error_params[window_size]}, Best Reconstruction Error: {best_error[window_size]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvRecurrentAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_params = {}\n",
    "best_loss = {}\n",
    "best_error_params = {}\n",
    "best_error = {}\n",
    "for window_size in window_sizes:\n",
    "    best_loss_params[window_size] = None\n",
    "    best_loss[window_size] = float('inf')\n",
    "    best_error_params[window_size] = None\n",
    "    best_error[window_size] = float('inf')\n",
    "\n",
    "param_grid = {\n",
    "    'window_size': window_sizes,         # Window sizes to test\n",
    "    'hidden_dim': [32, 64, 128, 256],    # Number of hidden dimensions\n",
    "    'kernel_size': [3, 5, 7, 9],         # Kernel sizes for convolution\n",
    "    'num_layers': [1, 2, 3, 6],          # Number of GRU layers\n",
    "    'learning_rate': [1e-3, 5e-4, 1e-4], # Learning rates\n",
    "    'epochs': [30],                         # Number of epochs (fixed for quick testing)\n",
    "}\n",
    "\n",
    "print(f\"#\"*(len('ConvRecurrentAutoencoder')+16))\n",
    "print(f\"###     ConvRecurrentAutoencoder     ###\")\n",
    "print(f\"#\"*(len('ConvRecurrentAutoencoder')+16))\n",
    "\n",
    "for params in ParameterGrid(param_grid):    \n",
    "    print(f\"\\tTesting parameters: {params}\")\n",
    "        \n",
    "    # Initialize the model with current parameters\n",
    "    model = ConvRecurrentAutoencoder(\n",
    "           input_dim=input_dim,\n",
    "           hidden_dim=params['hidden_dim'],\n",
    "           kernel_size=params['kernel_size'],\n",
    "           num_layers=params['num_layers']\n",
    "    ).to(device)\n",
    "\n",
    "    model, total_loss, avg_rec_error = train_and_evaluate(model=model, \n",
    "                                                          train_loader=train_benign_loader[window_sizes.index(params['window_size'])], \n",
    "                                                          test_loader=test_loader[window_sizes.index(params['window_size'])], \n",
    "                                                          optimizer=Adam(model.parameters(), lr=params['learning_rate']),\n",
    "                                                          epochs=params['epochs'], \n",
    "                                                          anomaly_weight=None, \n",
    "                                                          device=device)\n",
    "    print(f\"\\tTotal Loss: {total_loss}, Average Reconstruction Error: {avg_rec_error}\")\n",
    "\n",
    "    if total_loss < best_loss[params['window_size']]:\n",
    "        best_loss[params['window_size']] = total_loss\n",
    "        best_loss_params[params['window_size']] = params\n",
    "\n",
    "    if avg_rec_error < best_error[params['window_size']]:\n",
    "        best_error[params['window_size']] = avg_rec_error\n",
    "        best_error_params[params['window_size']] = params\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    print(f\"For Window Size = {window_size}:\")\n",
    "    print(f\"   TOTAL LOSS -- Best Parameters: {best_loss_params[window_size]}, Best Total Loss: {best_loss[window_size]}\")\n",
    "    print(f\"   AVERAGE RECONSTRUCTION ERROR -- Best Parameters: {best_error_params[window_size]}, Best Reconstruction Error: {best_error[window_size]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FullyConnectedAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_params = {}\n",
    "best_loss = {}\n",
    "best_error_params = {}\n",
    "best_error = {}\n",
    "for window_size in window_sizes:\n",
    "    best_loss_params[window_size] = None\n",
    "    best_loss[window_size] = float('inf')\n",
    "    best_error_params[window_size] = None\n",
    "    best_error[window_size] = float('inf')\n",
    "\n",
    "param_grid = {\n",
    "    'window_size': window_sizes,         # Window sizes to test\n",
    "    'hidden_dim': [32, 64, 128, 256],    # Number of hidden dimensions\n",
    "    'latent_dim': [16, 22, 32, 64],      # Latent dimension size\n",
    "    'num_layers': [1, 2, 3, 4, 6],       # Number of GRU layers\n",
    "    'learning_rate': [1e-3, 5e-4, 1e-4], # Learning rates\n",
    "    'epochs': [30],                         # Number of epochs (fixed for quick testing)\n",
    "}\n",
    "\n",
    "print(f\"#\"*(len('FullyConnectedAutoencoder')+16))\n",
    "print(f\"###     FullyConnectedAutoencoder     ###\")\n",
    "print(f\"#\"*(len('FullyConnectedAutoencoder')+16))\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\tTesting parameters: {params}\")\n",
    "        \n",
    "    # Initialize the model with current parameters\n",
    "    model = FullyConnectedAutoencoder(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=params['hidden_dim'],\n",
    "        latent_dim=params['latent_dim'],\n",
    "        num_layers=params['num_layers']\n",
    "    ).to(device)\n",
    "\n",
    "    model, total_loss, avg_rec_error = train_and_evaluate(model=model, \n",
    "                                                          train_loader=train_benign_loader[window_sizes.index(params['window_size'])], \n",
    "                                                          test_loader=test_loader[window_sizes.index(params['window_size'])], \n",
    "                                                          optimizer=Adam(model.parameters(), lr=params['learning_rate']),\n",
    "                                                          epochs=params['epochs'], \n",
    "                                                          anomaly_weight=None, \n",
    "                                                          device=device)\n",
    "    print(f\"\\tTotal Loss: {total_loss}, Average Reconstruction Error: {avg_rec_error}\")\n",
    "\n",
    "    if total_loss < best_loss[params['window_size']]:\n",
    "        best_loss[params['window_size']] = total_loss\n",
    "        best_loss_params[params['window_size']] = params\n",
    "\n",
    "    if avg_rec_error < best_error[params['window_size']]:\n",
    "        best_error[params['window_size']] = avg_rec_error\n",
    "        best_error_params[params['window_size']] = params\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    print(f\"For Window Size = {window_size}:\")\n",
    "    print(f\"   TOTAL LOSS -- Best Parameters: {best_loss_params[window_size]}, Best Total Loss: {best_loss[window_size]}\")\n",
    "    print(f\"   AVERAGE RECONSTRUCTION ERROR -- Best Parameters: {best_error_params[window_size]}, Best Reconstruction Error: {best_error[window_size]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Benign Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "anomaly_weight = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "models_path = 'models/'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters for benign models\n",
    "### NOTE: fill out for all window sizes based on the results of the grid search\n",
    "best_benign_params = {\n",
    "    1 : { \n",
    "        # 'TransformerAutoencoder': {'embed_dim': ..., 'epochs': ..., 'ff_dim': ..., 'learning_rate': ..., 'num_heads': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight},\n",
    "        # 'ConvRecurrentAutoencoder': {'epochs': ..., 'hidden_dim': ..., 'kernel_size': ..., 'learning_rate': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight},\n",
    "        # 'FullyConnectedAutoencoder': {'epochs': ..., 'hidden_dim': ..., 'latent_dim': ..., 'learning_rate': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight}\n",
    "    },\n",
    "    2 : { \n",
    "        # 'TransformerAutoencoder': {'embed_dim': ..., 'epochs': ..., 'ff_dim': ..., 'learning_rate': ..., 'num_heads': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight},\n",
    "        # 'ConvRecurrentAutoencoder': {'epochs': ..., 'hidden_dim': ..., 'kernel_size': ..., 'learning_rate': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight},\n",
    "        # 'FullyConnectedAutoencoder': {'epochs': ..., 'hidden_dim': ..., 'latent_dim': ..., 'learning_rate': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight}\n",
    "    },\n",
    "    8 : {\n",
    "        # 'TransformerAutoencoder': {'embed_dim': ..., 'epochs': ..., 'ff_dim': ..., 'learning_rate': ..., 'num_heads': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight},\n",
    "        # 'ConvRecurrentAutoencoder': {'epochs': ..., 'hidden_dim': ..., 'kernel_size': ..., 'learning_rate': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight},\n",
    "        # 'FullyConnectedAutoencoder': {'epochs': ..., 'hidden_dim': ..., 'latent_dim': ..., 'learning_rate': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight}\n",
    "    },\n",
    "    16 : { \n",
    "        # 'TransformerAutoencoder': {'embed_dim': ..., 'epochs': ..., 'ff_dim': ..., 'learning_rate': ..., 'num_heads': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight},\n",
    "        # 'ConvRecurrentAutoencoder': {'epochs': ..., 'hidden_dim': ..., 'kernel_size': ..., 'learning_rate': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight},\n",
    "        # 'FullyConnectedAutoencoder': {'epochs': ..., 'hidden_dim': ..., 'latent_dim': ..., 'learning_rate': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight}\n",
    "    },\n",
    "    32 : { \n",
    "        # 'TransformerAutoencoder': {'embed_dim': ..., 'epochs': ..., 'ff_dim': ..., 'learning_rate': ..., 'num_heads': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight},\n",
    "        # 'ConvRecurrentAutoencoder': {'epochs': ..., 'hidden_dim': ..., 'kernel_size': ..., 'learning_rate': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight},\n",
    "        # 'FullyConnectedAutoencoder': {'epochs': ..., 'hidden_dim': ..., 'latent_dim': ..., 'learning_rate': ..., 'num_layers': ..., 'anomaly_weight': anomaly_weight}\n",
    "    }\n",
    "}\n",
    "\n",
    "best_benign_models = {}\n",
    "benign_rec_errs = {}\n",
    "benign_smooth_rec_errs = {}\n",
    "for window_size in window_sizes:\n",
    "    best_benign_models[window_size], benign_rec_errs[window_size], benign_smooth_rec_errs[window_size] = train_all(models_path=models_path, \n",
    "                                                                                                                   models_type=\"benign\", \n",
    "                                                                                                                   best_params=best_benign_params[window_size], \n",
    "                                                                                                                   anomaly_weight = {\n",
    "                                                                                                                       'TransformerAutoencoder': best_benign_params[window_size]['TransformerAutoencoder']['anomaly_weight'],\n",
    "                                                                                                                       'ConvRecurrentAutoencoder': best_benign_params[window_size]['ConvRecurrentAutoencoder']['anomaly_weight'],\n",
    "                                                                                                                       'FullyConnectedAutoencoder': best_benign_params[window_size]['FullyConnectedAutoencoder']['anomaly_weight']\n",
    "                                                                                                                       },\n",
    "                                                                                                                   train_loader=train_benign_loader[window_sizes.index(window_size)], \n",
    "                                                                                                                   test_loader=test_loader[window_sizes.index(window_size)], \n",
    "                                                                                                                   window_size=window_size, \n",
    "                                                                                                                   input_dim=input_dim, \n",
    "                                                                                                                   device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for window_size in window_sizes:\n",
    "    for ae_name in ['TransformerAutoencoder', 'ConvRecurrentAutoencoder', 'FullyConnectedAutoencoder']:\n",
    "        model = best_benign_models[window_size][ae_name]\n",
    "        rec_err = benign_rec_errs[window_size][ae_name]\n",
    "        smooth_rec_errs = benign_smooth_rec_errs[window_size][ae_name]\n",
    "        \n",
    "        # Load total_loss\n",
    "        errors = []\n",
    "        colors = [\"blue\", \"orange\", \"green\", \"red\", \"purple\", \"brown\", \"pink\", \"gray\", \"olive\", \"cyan\", \"magenta\", \"navy\", \"teal\", \"maroon\", \"gold\"]\n",
    "        for idx, filter_size in enumerate(filter_sizes):\n",
    "            errors.append((smooth_rec_errs[filter_size], f\"fs_{filter_size}\", colors[idx]))\n",
    "        \n",
    "        plot_reconstruction_errors(attack_indices=list(range(len(test_attacks_indices))),\n",
    "                                   attack_index_intervals=test_attacks_index_intervals,\n",
    "                                   window_size = window_size,\n",
    "                                   reconstruction_errors = errors,\n",
    "                                   sufix = f\" - {ae_name}, window size={window_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate model performance\n",
    "model_performance_benign = {}\n",
    "detected_attacks_benign = {}\n",
    "precision = {}\n",
    "recall = {}\n",
    "\n",
    "for ae_name in ['TransformerAutoencoder', 'ConvRecurrentAutoencoder', 'FullyConnectedAutoencoder']:\n",
    "  print(f\"#####   Calculate model performance for {ae_name}   #####\")\n",
    "\n",
    "  model_performance_benign[ae_name] = []\n",
    "  detected_attacks_benign[ae_name] = []\n",
    "  precision[ae_name] = []\n",
    "  recall[ae_name] = []\n",
    "\n",
    "  # Calculate model performance for all window sizes for all filter sizes\n",
    "  for window_size in window_sizes:\n",
    "    # Adjust indices to account for the window size - First-Point Strategy\n",
    "    adjusted_indices = test_attacks_indices[:-window_size] \n",
    "    for filter_size in filter_sizes:\n",
    "      model_performance_tmp, detected_attacks_tmp, precision_tmp, recall_tmp = calculate_model_performance(test_ground_truth_labels=adjusted_indices, \n",
    "                                                                                                           reconstruction_errors=benign_smooth_rec_errs[window_size][ae_name][filter_size], \n",
    "                                                                                                           method_name=f'{ae_name}_ws{window_size}_fs{filter_size}')\n",
    "      model_performance_benign[ae_name].append(model_performance_tmp)\n",
    "      detected_attacks_benign[ae_name].append(detected_attacks_tmp)\n",
    "      precision[ae_name].append(precision_tmp)\n",
    "      recall[ae_name].append(recall_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    pd.concat(model_performance_benign['TransformerAutoencoder']), \n",
    "    pd.concat(model_performance_benign['ConvRecurrentAutoencoder']),\n",
    "    pd.concat(model_performance_benign['FullyConnectedAutoencoder'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_segments_for_ae_and_ws_fs = {}\n",
    "real_segments_for_ae_and_ws_fs = {}\n",
    "removed_real_segments_for_ae_and_ws_fs = {}\n",
    "\n",
    "for ae_name in ['TransformerAutoencoder', 'ConvRecurrentAutoencoder', 'FullyConnectedAutoencoder']:\n",
    "\n",
    "  detected_segments_for_ae_and_ws_fs[ae_name] = {}\n",
    "  real_segments_for_ae_and_ws_fs[ae_name] = {}\n",
    "  removed_real_segments_for_ae_and_ws_fs[ae_name] = {}\n",
    "  \n",
    "  print(\"#\"*len(f'#####   {ae_name}   #####'))\n",
    "  print(f\"#####   {ae_name}   #####\")\n",
    "  print(\"#\"*len(f'#####   {ae_name}   #####'))\n",
    "  for idx1, window_size in enumerate(window_sizes):\n",
    "\n",
    "    detected_segments_for_ae_and_ws_fs[ae_name][window_size] = {}\n",
    "    real_segments_for_ae_and_ws_fs[ae_name][window_size] = {}\n",
    "    removed_real_segments_for_ae_and_ws_fs[ae_name][window_size] = {}\n",
    "\n",
    "    print(f\"#####\")\n",
    "    print(f\"##### window_size: {window_size} #####\")\n",
    "    print(f\"#####\")\n",
    "    for idx2, filter_size in enumerate(filter_sizes):\n",
    "      print(f\"###\")\n",
    "      print(f\"### filter_size: {filter_size} ###\")\n",
    "      print(f\"###\")\n",
    "\n",
    "      detected_segments = find_segments(detected_attacks_benign[ae_name][len(filter_sizes)*idx1+idx2])\n",
    "      real_segments = find_segments(test_attacks_indices[:-window_size])\n",
    "      removed_real_segments_for_ae_and_ws_fs[ae_name][window_size][filter_size] = 0\n",
    "      print(f\"Detected segments: {detected_segments}\")\n",
    "      print(f\"Real segments: {real_segments}\")\n",
    "\n",
    "      i = 0\n",
    "      j = 0\n",
    "      detected_segments_tmp = []\n",
    "      real_segments_tmp = []\n",
    "      while i<len(detected_segments) and j<len(real_segments):\n",
    "          if detected_segments[i][1] <= real_segments[j][0]:\n",
    "            i+=1\n",
    "          elif (detected_segments[i][0] < real_segments[j][1]) and (real_segments[j][0] < detected_segments[i][1]):\n",
    "            detected_segments_tmp.append(detected_segments[i])\n",
    "            real_segments_tmp.append(real_segments[j])\n",
    "            i+=1\n",
    "            j+=1\n",
    "            while i<len(detected_segments) and j<len(real_segments) and (detected_segments[i][1] < real_segments[j][0]):\n",
    "              i+=1\n",
    "            while i<len(detected_segments) and j<len(real_segments) and (real_segments[j][1] < detected_segments[i][0]):\n",
    "              removed_real_segments_for_ae_and_ws_fs[ae_name][window_size][filter_size]+=1\n",
    "              j+=1\n",
    "          elif real_segments[j][1] <= detected_segments[i][0] :\n",
    "            removed_real_segments_for_ae_and_ws_fs[ae_name][window_size][filter_size]+=1\n",
    "            j+=1\n",
    "\n",
    "      detected_attacks_tmp  = np.zeros(detected_attacks_benign[ae_name][len(filter_sizes)*idx1+idx2].shape[0])\n",
    "      for attack in detected_segments_tmp:\n",
    "          detected_attacks_tmp[attack[0]:attack[1]+1] = 1\n",
    "      real_attacks_tmp  = np.zeros(test_attacks_indices[:-window_size].shape[0])\n",
    "      for attack in real_segments_tmp:\n",
    "          real_attacks_tmp[attack[0]:attack[1]+1] = 1\n",
    "\n",
    "      detected_segments_for_ae_and_ws_fs[ae_name][window_size][filter_size] = find_segments(detected_attacks_tmp)\n",
    "      real_segments_for_ae_and_ws_fs[ae_name][window_size][filter_size] = find_segments(real_attacks_tmp)\n",
    "      print(f\"Detected segments to compare: {detected_segments_for_ae_and_ws_fs[ae_name][window_size][filter_size]}\")\n",
    "      print(f\"Real segments to compare: {real_segments_for_ae_and_ws_fs[ae_name][window_size][filter_size]}\")\n",
    "      print(f\"Removed real segments: {removed_real_segments_for_ae_and_ws_fs[ae_name][window_size][filter_size]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ae_name in ['TransformerAutoencoder', 'ConvRecurrentAutoencoder', 'FullyConnectedAutoencoder']:\n",
    "    \n",
    "    for idx1, window_size in enumerate(window_sizes):\n",
    "        for idx2, filter_size in enumerate(filter_sizes):\n",
    "        \n",
    "            detected_attacks_len = len(find_segments(detected_attacks_benign[ae_name][len(filter_sizes)*idx1+idx2]))\n",
    "            detected_segments = detected_segments_for_ae_and_ws_fs[ae_name][window_size][filter_size]\n",
    "            method = f'{ae_name}_ws{window_size}_fs{filter_size}'\n",
    "            results = model_performance_benign[ae_name][len(filter_sizes)*idx1+idx2]\n",
    "\n",
    "            print(\"#\"*len(f'#####   {method}   #####'))\n",
    "            print(f\"#####   {method}   #####\")\n",
    "            print(\"#\"*len(f'#####   {method}   #####'))\n",
    "            \n",
    "            real_segments = real_segments_for_ae_and_ws_fs[ae_name][window_size][filter_size]\n",
    "            assert len(detected_segments) == len(real_segments), f\"Segments lists must have the same length [{len(detected_segments)}<>{len(real_segments)}].\"\n",
    "\n",
    "            results['num_of_detected'] = detected_attacks_len\n",
    "\n",
    "            ttd = 0\n",
    "            for detected_segment, real_segment in zip(detected_segments, real_segments):\n",
    "                ttd = ttd + max((detected_segment[0] - real_segment[0]), 0)/real_segment[2]\n",
    "            ttd = ttd + removed_real_segments_for_ae_and_ws_fs[ae_name][window_size][filter_size]\n",
    "            Sttd = 1-ttd/len(find_segments(test_attacks_indices[:-window_size]))\n",
    "\n",
    "            gama = 0.5\n",
    "            Sclf = results['Sclf'].values[0]\n",
    "            S = gama * Sttd + (1-gama) * Sclf\n",
    "\n",
    "            print(f\"Sttd = {Sttd}, S = {S}\")\n",
    "            results['Sttd'] = Sttd\n",
    "            results['S'] = S\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    pd.concat(model_performance_benign['TransformerAutoencoder']), \n",
    "    pd.concat(model_performance_benign['ConvRecurrentAutoencoder']),\n",
    "    pd.concat(model_performance_benign['FullyConnectedAutoencoder'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# visualize\n",
    "f, ax = plt.subplots(1,figsize=(7,7))\n",
    "\n",
    "lw = 3\n",
    "font_size = 15\n",
    "\n",
    "ls = \t'-'\n",
    "\n",
    "for ae_name, ae_label, color in [('TransformerAutoencoder', \"TransAE\", \"blue\"), \n",
    "                                 ('ConvRecurrentAutoencoder', \"ConvRecAE\", \"red\"), \n",
    "                                 ('FullyConnectedAutoencoder', \"FCAE\", \"green\")]:\n",
    "    ax.plot(model_performance_benign[ae_name][0][\"fpr\"].iloc[0], \n",
    "            model_performance_benign[ae_name][0][\"tpr\"].iloc[0], \n",
    "            linewidth=lw, linestyle= ls, label='{}'.format(f\"{ae_label}, ws=1\"), color=color, alpha=0.2)\n",
    "    ax.plot(model_performance_benign[ae_name][1][\"fpr\"].iloc[0], \n",
    "            model_performance_benign[ae_name][1][\"tpr\"].iloc[0], \n",
    "            linewidth=lw, linestyle= ls, label='{}'.format(f\"{ae_label}, ws=2\"), color=color, alpha=0.4)\n",
    "    ax.plot(model_performance_benign[ae_name][2][\"fpr\"].iloc[0], \n",
    "            model_performance_benign[ae_name][2][\"tpr\"].iloc[0], \n",
    "            linewidth=lw, linestyle= ls, label='{}'.format(f\"{ae_label}, ws=8\"), color=color, alpha=0.6)\n",
    "    ax.plot(model_performance_benign[ae_name][3][\"fpr\"].iloc[0], \n",
    "            model_performance_benign[ae_name][3][\"tpr\"].iloc[0], \n",
    "            linewidth=lw, linestyle= ls, label='{}'.format(f\"{ae_label}, ws=16\"), color=color, alpha=0.8)\n",
    "    ax.plot(model_performance_benign[ae_name][4][\"fpr\"].iloc[0], \n",
    "            model_performance_benign[ae_name][4][\"tpr\"].iloc[0], \n",
    "            linewidth=lw, linestyle= ls, label='{}'.format(f\"{ae_label}, ws=32\"), color=color, alpha=1)\n",
    "\n",
    "# axes label size\n",
    "ax.set_xlabel(\"False Positive Rate\", fontsize=font_size)\n",
    "ax.set_ylabel(\"True Positive Rate\", fontsize=font_size)\n",
    "\n",
    "# Tick label size\n",
    "ax.tick_params(axis='x', labelsize=font_size)\n",
    "ax.tick_params(axis='y', labelsize=font_size)\n",
    "\n",
    "# set y lim\n",
    "ax.set_ylim(0.495, 1.005)\n",
    "\n",
    "ax.legend(fontsize=font_size)\n",
    "# Legend 1: Based on color (AE)\n",
    "legend1 = ax.legend(\n",
    "    handles=[\n",
    "        Line2D([0], [0], color='blue', lw=lw, label=f'Trans'),\n",
    "        Line2D([0], [0], color='red', lw=lw, label=f'ConvRec'),\n",
    "        Line2D([0], [0], color='green', lw=lw, label=fr'FC'),\n",
    "    ],\n",
    "    loc='center right',\n",
    "    title='Autoencoders',\n",
    "    fontsize=font_size\n",
    ")\n",
    "# Set the font size of the legend title after creation\n",
    "if legend1.get_title():  # Check if there is a title\n",
    "    legend1.get_title().set_fontsize(font_size) # Use the font_size variable\n",
    "ax.add_artist(legend1)  # Add the first legend manually\n",
    "\n",
    "# Legend 2: Based on color intensity (ws)\n",
    "intensities = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "legend2 = ax.legend(\n",
    "    handles=[\n",
    "        Patch(facecolor='gray', alpha=alpha, label=f'{ws}')\n",
    "        for ws, alpha in [(1, 0.2),(2, 0.4),(8, 0.6),(16, 0.8),(32, 1.0)]\n",
    "    ],\n",
    "    loc='lower right',\n",
    "    title='window size',\n",
    "    fontsize=font_size\n",
    ")\n",
    "# Set the font size of the legend title after creation\n",
    "if legend2.get_title():  # Check if there is a title\n",
    "    legend2.get_title().set_fontsize(font_size) # Use the font_size variable\n",
    "\n",
    "\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# visualize\n",
    "f, ax = plt.subplots(1,figsize=(7,7))\n",
    "\n",
    "lw = 3\n",
    "font_size = 15\n",
    "\n",
    "\n",
    "for ae_name, ae_label, color in [('TransformerAutoencoder', \"TransAE\", \"blue\"), \n",
    "                                 ('ConvRecurrentAutoencoder', \"ConvRecAE\", \"red\"), \n",
    "                                 ('FullyConnectedAutoencoder', \"FCAE\", \"green\")]:\n",
    "    ax.plot(model_performance_benign[ae_name][15*2+12][\"fpr\"].iloc[0], \n",
    "            model_performance_benign[ae_name][15*2+12][\"tpr\"].iloc[0], \n",
    "            linewidth=lw, linestyle= None, label='{}'.format(f\"{ae_label}, fs=25\"), color=color, alpha=1)\n",
    "    ax.plot(model_performance_benign[ae_name][15*2+11][\"fpr\"].iloc[0], \n",
    "            model_performance_benign[ae_name][15*2+11][\"tpr\"].iloc[0], \n",
    "            linewidth=lw, linestyle= None, label='{}'.format(f\"{ae_label}, fs=23\"), color=color, alpha=0.8)\n",
    "    ax.plot(model_performance_benign[ae_name][15*2+10][\"fpr\"].iloc[0], \n",
    "            model_performance_benign[ae_name][15*2+10][\"tpr\"].iloc[0], \n",
    "            linewidth=lw, linestyle= None, label='{}'.format(f\"{ae_label}, fs=21\"), color=color, alpha=0.6)\n",
    "    ax.plot(model_performance_benign[ae_name][15*2+9][\"fpr\"].iloc[0], \n",
    "            model_performance_benign[ae_name][15*2+9][\"tpr\"].iloc[0], \n",
    "            linewidth=lw, linestyle= None, label='{}'.format(f\"{ae_label}, fs=19\"), color=color, alpha=0.3)\n",
    "    ax.plot(model_performance_benign[ae_name][15*2+8][\"fpr\"].iloc[0], \n",
    "            model_performance_benign[ae_name][15*2+8][\"tpr\"].iloc[0], \n",
    "            linewidth=lw, linestyle= None, label='{}'.format(f\"{ae_label}, fs=17\"), color=color, alpha=0.1)\n",
    "\n",
    "# axes label size\n",
    "ax.set_xlabel(\"False Positive Rate\", fontsize=font_size)\n",
    "ax.set_ylabel(\"True Positive Rate\", fontsize=font_size)\n",
    "\n",
    "# Tick label size\n",
    "ax.tick_params(axis='x', labelsize=font_size)\n",
    "ax.tick_params(axis='y', labelsize=font_size)\n",
    "\n",
    "# set y lim\n",
    "ax.set_ylim(0.955, 1.005)\n",
    "\n",
    "ax.legend(fontsize=font_size)\n",
    "# Legend 1: Based on color (AE)\n",
    "legend1 = ax.legend(\n",
    "    handles=[\n",
    "        Line2D([0], [0], color='blue', lw=lw, label=f'Trans'),\n",
    "        Line2D([0], [0], color='red', lw=lw, label=f'ConvRec'),\n",
    "        Line2D([0], [0], color='green', lw=lw, label=fr'FC'),\n",
    "    ],\n",
    "    loc='center right',\n",
    "    title='Autoencoders',\n",
    "    fontsize=font_size\n",
    ")\n",
    "# Set the font size of the legend title after creation\n",
    "if legend1.get_title():  # Check if there is a title\n",
    "    legend1.get_title().set_fontsize(font_size) # Use the font_size variable\n",
    "ax.add_artist(legend1)  # Add the first legend manually\n",
    "\n",
    "# Legend 2: Based on color intensity (fs)\n",
    "legend2 = ax.legend(\n",
    "    handles=[\n",
    "        Patch(facecolor='gray', alpha=alpha, label=f'{fs}')\n",
    "        for fs, alpha in [(17, 0.1),(19, 0.3),(21, 0.6),(23, 0.8),(25, 1.0)]\n",
    "    ],\n",
    "    loc='lower right',\n",
    "    title='filter size',\n",
    "    fontsize=font_size\n",
    ")\n",
    "# Set the font size of the legend title after creation\n",
    "if legend2.get_title():  # Check if there is a title\n",
    "    legend2.get_title().set_fontsize(font_size) # Use the font_size variable\n",
    "ax.add_artist(legend2)  # Add the first legend manually\n",
    "\n",
    "legend3 = ax.legend(\n",
    "    handles=[],\n",
    "    loc='upper left',\n",
    "    title='ws=8',\n",
    ")\n",
    "# Set the font size of the legend title after creation\n",
    "if legend3.get_title():  # Check if there is a title\n",
    "    legend3.get_title().set_fontsize(font_size) # Use the font_size variable\n",
    "\n",
    "\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Attackaware Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "anomaly_weights = [-0.1,-0.2,-0.3,-0.4,-0.5,-0.6,-0.7,-0.8,-0.9,-1]\n",
    "window_size = 8 # We fix window size to 8 for attackaware models\n",
    "filter_size = 21 # We fix filter size to 21 for attackaware models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "models_path = 'models/'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters for attackaware models\n",
    "best_attackaware_params = {\n",
    "    ### NOTE: fill out for window size = 8 based on the results of the grid search\n",
    "    8 : { \n",
    "        # 'TransformerAutoencoder': {'embed_dim': ..., 'epochs': ..., 'ff_dim': ..., 'learning_rate': ..., 'num_heads': ..., 'num_layers': ..., 'anomaly_weight': ...},\n",
    "        # 'ConvRecurrentAutoencoder': {'epochs': ..., 'hidden_dim': ..., 'kernel_size': ..., 'learning_rate': ..., 'num_layers': ..., 'anomaly_weight': ...},\n",
    "        # 'FullyConnectedAutoencoder': {'epochs': ..., 'hidden_dim': ..., 'latent_dim': ..., 'learning_rate': ..., 'num_layers': ..., 'anomaly_weight': ...}\n",
    "    },\n",
    "}\n",
    "\n",
    "best_attackaware_models = {}\n",
    "attackaware_rec_errs = {}\n",
    "attackaware_smooth_rec_errs = {}\n",
    "\n",
    "for anomaly_weight in anomaly_weights:\n",
    "    best_attackaware_models[anomaly_weight], attackaware_rec_errs[anomaly_weight], attackaware_smooth_rec_errs[anomaly_weight] = train_all(models_path=models_path, \n",
    "                                                                                                                                           models_type=\"attackaware\", \n",
    "                                                                                                                                           best_params=best_attackaware_params[window_size], \n",
    "                                                                                                                                           anomaly_weight = {\n",
    "                                                                                                                                               'TransformerAutoencoder': anomaly_weight,\n",
    "                                                                                                                                               'ConvRecurrentAutoencoder': anomaly_weight,\n",
    "                                                                                                                                               'FullyConnectedAutoencoder': anomaly_weight\n",
    "                                                                                                                                               },\n",
    "                                                                                                                                           train_loader=train_attack_loader[window_sizes.index(window_size)],\n",
    "                                                                                                                                           test_loader=test_loader[window_sizes.index(window_size)], \n",
    "                                                                                                                                           window_size=window_size, \n",
    "                                                                                                                                           input_dim=input_dim, \n",
    "                                                                                                                                           device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ae_name in ['TransformerAutoencoder', 'ConvRecurrentAutoencoder', 'FullyConnectedAutoencoder']:\n",
    "\n",
    "    # Load total_loss\n",
    "    errors = []\n",
    "    colors = [\"blue\", \"orange\", \"green\", \"red\", \"purple\", \"brown\", \"pink\", \"gray\", \"olive\", \"cyan\", \"magenta\", \"navy\", \"teal\", \"maroon\", \"gold\"]\n",
    "\n",
    "    for idx, anomaly_weight in enumerate(anomaly_weights):\n",
    "        model = best_attackaware_models[anomaly_weight][ae_name]\n",
    "        rec_err = attackaware_rec_errs[anomaly_weight][ae_name]\n",
    "        smooth_rec_errs = attackaware_smooth_rec_errs[anomaly_weight][ae_name]\n",
    "        \n",
    "        errors.append((smooth_rec_errs[filter_size], f\"aw_{anomaly_weight}\", colors[idx]))\n",
    "        \n",
    "    plot_reconstruction_errors(attack_indices=list(range(len(test_attacks_indices))),\n",
    "                               attack_index_intervals=test_attacks_index_intervals,\n",
    "                               window_size = window_size,\n",
    "                               reconstruction_errors = errors,\n",
    "                               sufix = f\" - {ae_name}, window size={window_size}, filter size={filter_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate model performance\n",
    "model_performance_attackaware = {}\n",
    "detected_attacks_attackaware = {}\n",
    "precision = {}\n",
    "recall = {}\n",
    "\n",
    "for ae_name in ['TransformerAutoencoder', 'ConvRecurrentAutoencoder', 'FullyConnectedAutoencoder']:\n",
    "  print(f\"#####   Calculate model performance for {ae_name}   #####\")\n",
    "\n",
    "  model_performance_attackaware[ae_name] = []\n",
    "  detected_attacks_attackaware[ae_name] = []\n",
    "  precision[ae_name] = []\n",
    "  recall[ae_name] = []\n",
    "\n",
    "  adjusted_indices = test_attacks_indices[:-window_size] \n",
    "\n",
    "  # Calculate model performance for all anomaly weights for the fixed window size and filter size\n",
    "  for idx, anomaly_weight in enumerate(anomaly_weights):\n",
    "      \n",
    "      model_performance_tmp, detected_attacks_tmp, precision_tmp, recall_tmp = calculate_model_performance(test_ground_truth_labels=adjusted_indices, \n",
    "                                                                                                           reconstruction_errors=attackaware_smooth_rec_errs[anomaly_weight][ae_name][filter_size], \n",
    "                                                                                                           method_name=f'{ae_name}_ws{window_size}_fs{filter_size}_aw{anomaly_weight}')\n",
    "      model_performance_attackaware[ae_name].append(model_performance_tmp)\n",
    "      detected_attacks_attackaware[ae_name].append(detected_attacks_tmp)\n",
    "      precision[ae_name].append(precision_tmp)\n",
    "      recall[ae_name].append(recall_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    pd.concat(model_performance_attackaware['TransformerAutoencoder']), \n",
    "    pd.concat(model_performance_attackaware['ConvRecurrentAutoencoder']),\n",
    "    pd.concat(model_performance_attackaware['FullyConnectedAutoencoder'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_segments_for_ae_and_ws_fs = {}\n",
    "real_segments_for_ae_and_ws_fs = {}\n",
    "removed_real_segments_for_ae_and_ws_fs = {}\n",
    "\n",
    "for ae_name in ['TransformerAutoencoder', 'ConvRecurrentAutoencoder', 'FullyConnectedAutoencoder']:\n",
    "\n",
    "  detected_segments_for_ae_and_ws_fs[ae_name] = {}\n",
    "  real_segments_for_ae_and_ws_fs[ae_name] = {}\n",
    "  removed_real_segments_for_ae_and_ws_fs[ae_name] = {}\n",
    "  \n",
    "  print(\"#\"*len(f'#####   {ae_name}   #####'))\n",
    "  print(f\"#####   {ae_name}   #####\")\n",
    "  print(\"#\"*len(f'#####   {ae_name}   #####'))\n",
    "  for idx, anomaly_weight in enumerate(anomaly_weights):\n",
    "      print(\"#\"*len(f'###   {anomaly_weight}   ###'))\n",
    "      print(f\"###   {anomaly_weight}   ###\")\n",
    "      print(\"#\"*len(f'###   {anomaly_weight}   ###'))\n",
    "   \n",
    "      detected_segments = find_segments(detected_attacks_attackaware[ae_name][idx])\n",
    "      real_segments = find_segments(test_attacks_indices[:-window_size])\n",
    "      removed_real_segments_for_ae_and_ws_fs[ae_name][anomaly_weight] = 0\n",
    "      print(f\"Detected segments: {detected_segments}\")\n",
    "      print(f\"Real segments: {real_segments}\")\n",
    "\n",
    "      i = 0\n",
    "      j = 0\n",
    "      detected_segments_tmp = []\n",
    "      real_segments_tmp = []\n",
    "      while i<len(detected_segments) and j<len(real_segments):\n",
    "          if detected_segments[i][1] <= real_segments[j][0]:\n",
    "            i+=1\n",
    "          elif (detected_segments[i][0] < real_segments[j][1]) and (real_segments[j][0] < detected_segments[i][1]):\n",
    "            detected_segments_tmp.append(detected_segments[i])\n",
    "            real_segments_tmp.append(real_segments[j])\n",
    "            i+=1\n",
    "            j+=1\n",
    "            while i<len(detected_segments) and j<len(real_segments) and (detected_segments[i][1] < real_segments[j][0]):\n",
    "              i+=1\n",
    "            while i<len(detected_segments) and j<len(real_segments) and (real_segments[j][1] < detected_segments[i][0]):\n",
    "              removed_real_segments_for_ae_and_ws_fs[ae_name][anomaly_weight]+=1\n",
    "              j+=1\n",
    "          elif real_segments[j][1] <= detected_segments[i][0]:\n",
    "            removed_real_segments_for_ae_and_ws_fs[ae_name][anomaly_weight]+=1\n",
    "            j+=1\n",
    "      detected_attacks_tmp  = np.zeros(detected_attacks_attackaware[ae_name][idx].shape[0])\n",
    "      for attack in detected_segments_tmp:\n",
    "          detected_attacks_tmp[attack[0]:attack[1]+1] = 1\n",
    "      real_attacks_tmp  = np.zeros(test_attacks_indices[:-window_size].shape[0])\n",
    "      for attack in real_segments_tmp:\n",
    "          real_attacks_tmp[attack[0]:attack[1]+1] = 1\n",
    "\n",
    "      detected_segments_for_ae_and_ws_fs[ae_name][anomaly_weight] = find_segments(detected_attacks_tmp)\n",
    "      real_segments_for_ae_and_ws_fs[ae_name][anomaly_weight] = find_segments(real_attacks_tmp)\n",
    "      print(f\"Detected segments to compare: {detected_segments_for_ae_and_ws_fs[ae_name][anomaly_weight]}\")\n",
    "      print(f\"Real segments to compare: {real_segments_for_ae_and_ws_fs[ae_name][anomaly_weight]}\")\n",
    "      print(f\"Removed real segments: {removed_real_segments_for_ae_and_ws_fs[ae_name][anomaly_weight]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ae_name in ['TransformerAutoencoder', 'ConvRecurrentAutoencoder', 'FullyConnectedAutoencoder']:\n",
    "    \n",
    "    for idx, anomaly_weight in enumerate(anomaly_weights):\n",
    "        \n",
    "        detected_attacks_len = len(find_segments(detected_attacks_attackaware[ae_name][idx]))\n",
    "        detected_segments = detected_segments_for_ae_and_ws_fs[ae_name][anomaly_weight]\n",
    "        method = f'{ae_name}_ws{window_size}_fs{filter_size}'\n",
    "        results = model_performance_attackaware[ae_name][idx]\n",
    "\n",
    "        print(\"#\"*len(f'#####   {method}   #####'))\n",
    "        print(f\"#####   {method}   #####\")\n",
    "        print(\"#\"*len(f'#####   {method}   #####'))\n",
    "            \n",
    "        real_segments = real_segments_for_ae_and_ws_fs[ae_name][anomaly_weight]\n",
    "        assert len(detected_segments) == len(real_segments), f\"Segments lists must have the same length [{len(detected_segments)}<>{len(real_segments)}].\"\n",
    "\n",
    "        results['num_of_detected'] = detected_attacks_len\n",
    "\n",
    "        ttd = 0\n",
    "        for detected_segment, real_segment in zip(detected_segments, real_segments):\n",
    "            ttd = ttd + max((detected_segment[0] - real_segment[0]), 0)/real_segment[2]\n",
    "        ttd = ttd + removed_real_segments_for_ae_and_ws_fs[ae_name][anomaly_weight]\n",
    "        Sttd = 1-ttd/len(find_segments(test_attacks_indices[:-window_size]))\n",
    "\n",
    "        gama = 0.5\n",
    "        Sclf = results['Sclf'].values[0]\n",
    "        S = gama * Sttd + (1-gama) * Sclf\n",
    "\n",
    "        print(f\"Sttd = {Sttd}, S = {S}\")\n",
    "        results['Sttd'] = Sttd\n",
    "        results['S'] = S\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    pd.concat(model_performance_attackaware['TransformerAutoencoder']), \n",
    "    pd.concat(model_performance_attackaware['ConvRecurrentAutoencoder']),\n",
    "    pd.concat(model_performance_attackaware['FullyConnectedAutoencoder'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualize\n",
    "f, ax = plt.subplots(1,figsize=(7,7))\n",
    "\n",
    "lw = 3\n",
    "font_size = 15\n",
    "\n",
    "ax.plot(model_performance_benign['TransformerAutoencoder'][15*2+12][\"fpr\"].iloc[0], \n",
    "        model_performance_benign['TransformerAutoencoder'][15*2+12][\"tpr\"].iloc[0], \n",
    "        linestyle='--', linewidth=lw, label='{}'.format(\"Benign TransAE, fs=21\"), color=\"blue\")\n",
    "ax.plot(model_performance_benign['ConvRecurrentAutoencoder'][15*2+12][\"fpr\"].iloc[0], \n",
    "        model_performance_benign['ConvRecurrentAutoencoder'][15*2+12][\"tpr\"].iloc[0], \n",
    "        linestyle='--', linewidth=lw, label='{}'.format(\"Benign ConvRecAE, fs=21\"), color=\"red\")\n",
    "ax.plot(model_performance_benign['FullyConnectedAutoencoder'][15*2+12][\"fpr\"].iloc[0], \n",
    "        model_performance_benign['FullyConnectedAutoencoder'][15*2+12][\"tpr\"].iloc[0], \n",
    "        linestyle='--', linewidth=lw, label='{}'.format(\"Benign FCAE, fs=21\"), color=\"green\")\n",
    "ax.plot(model_performance_attackaware['FullyConnectedAutoencoder'][4][\"fpr\"].iloc[0], \n",
    "        model_performance_attackaware['FullyConnectedAutoencoder'][4][\"tpr\"].iloc[0], \n",
    "        linestyle = None, linewidth=lw, label='{}'.format(\"Attack aware TransAE, fs=21\"), color=\"blue\")\n",
    "ax.plot(model_performance_attackaware['FullyConnectedAutoencoder'][4][\"fpr\"].iloc[0], \n",
    "        model_performance_attackaware['FullyConnectedAutoencoder'][4][\"tpr\"].iloc[0], \n",
    "        linestyle = None, linewidth=lw, label='{}'.format(\"Attack aware ConvRecAE, fs=21\"), color=\"red\")\n",
    "ax.plot(model_performance_attackaware['FullyConnectedAutoencoder'][4][\"fpr\"].iloc[0], \n",
    "        model_performance_attackaware['FullyConnectedAutoencoder'][4][\"tpr\"].iloc[0], \n",
    "        linestyle = None, linewidth=lw, label='{}'.format(\"Attack aware FCAE, fs=21\"), color=\"green\")\n",
    "\n",
    "# axes label size\n",
    "ax.set_xlabel(\"False Positive Rate\", fontsize=font_size)\n",
    "ax.set_ylabel(\"True Positive Rate\", fontsize=font_size)\n",
    "\n",
    "# Tick label size\n",
    "ax.tick_params(axis='x', labelsize=font_size)\n",
    "ax.tick_params(axis='y', labelsize=font_size)\n",
    "\n",
    "# set y lim\n",
    "ax.set_ylim(0.979, 1.001)\n",
    "\n",
    "# Legend 1: Based on color (Category)\n",
    "legend1 = ax.legend(\n",
    "    handles=[\n",
    "        Line2D([0], [0], color='blue', lw=lw, label=f'TransAE'),\n",
    "        Line2D([0], [0], color='red', lw=lw, label=f'ConvRecAE'),\n",
    "        Line2D([0], [0], color='green', lw=lw, label=fr'FCAE'),\n",
    "    ],\n",
    "    loc='lower right',\n",
    "    title='Attacked data',\n",
    "    fontsize=font_size\n",
    ")\n",
    "# Set the font size of the legend title after creation\n",
    "if legend1.get_title():  # Check if there is a title\n",
    "    legend1.get_title().set_fontsize(font_size) # Use the font_size variable\n",
    "ax.add_artist(legend1)  # Add the first legend manually\n",
    "\n",
    "# Legend 2: Based on linestyle (Method)\n",
    "legend2 = ax.legend(\n",
    "    handles=[\n",
    "        Line2D([0], [0], color='blue', linestyle='--', lw=lw, label=f'TransAE'),\n",
    "        Line2D([0], [0], color='red', linestyle='--', lw=lw, label=f'ConvRecAE'),\n",
    "        Line2D([0], [0], color='green', linestyle='--', lw=lw, label=f'FCAE'),\n",
    "    ],\n",
    "    loc='center right',\n",
    "    title='Benign data',\n",
    "    fontsize=font_size\n",
    ")\n",
    "# Set the font size of the legend title after creation\n",
    "if legend2.get_title():  # Check if there is a title\n",
    "    legend2.get_title().set_fontsize(font_size) # Use the font_size variable\n",
    "ax.add_artist(legend2)  # Add the first legend manually\n",
    "\n",
    "\n",
    "legend3 = ax.legend(\n",
    "    handles=[],\n",
    "    loc='upper right',\n",
    "    title='ws=8, fs=21',\n",
    ")\n",
    "# Set the font size of the legend title after creation\n",
    "if legend3.get_title():  # Check if there is a title\n",
    "    legend3.get_title().set_fontsize(font_size) # Use the font_size variable\n",
    "\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "len_test_datetime = 2089\n",
    "start_date = '2017-04-01 00:00:00'\n",
    "hourly_datetime_list = pd.date_range(start=start_date, periods=len_test_datetime, freq='h')[:-window_size]\n",
    "\n",
    "# load total_loss\n",
    "errors = [\n",
    "      (benign_smooth_rec_errs[window_size]['TransformerAutoencoder'][filter_size], f\"TransAE - ws=8, fs=21, benign data\", \"blue\"),\n",
    "      (benign_smooth_rec_errs[window_size]['ConvRecurrentAutoencoder'][filter_size], f\"ConvRecAE - ws=8, fs=21, benign data\", \"red\"),\n",
    "      (benign_smooth_rec_errs[window_size]['FullyConnectedAutoencoder'][filter_size], f\"FCAE - ws=8, fs=21, benign data\", \"green\"),\n",
    "      (attackaware_smooth_rec_errs[-0.2]['TransformerAutoencoder'][filter_size], f\"TransAE - ws=8, fs=21, aw=-0.2, attacked data\", \"blue\"),\n",
    "      (attackaware_smooth_rec_errs[-0.2]['ConvRecurrentAutoencoder'][filter_size], f\"ConvRecAE - ws=8, fs=21, aw=-0.2, attacked data\", \"red\"),\n",
    "      (attackaware_smooth_rec_errs[-0.2]['FullyConnectedAutoencoder'][filter_size], f\"FCAE - ws=8, fs=21, aw=-0.2, attacked data\", \"green\"),\n",
    "]\n",
    "\n",
    "\n",
    "# Plotting both reconstruction errors on a single plot\n",
    "plt.figure(figsize=(24, 4))\n",
    "\n",
    "lw = 3\n",
    "font_size = 15\n",
    "\n",
    "for (errors, label, color) in errors:\n",
    "    if 'benign' in label:\n",
    "        plt.plot(hourly_datetime_list, errors, linewidth=lw, label=label, color=color, linestyle='--')\n",
    "    else:\n",
    "        plt.plot(hourly_datetime_list, errors, linewidth=lw, label=label, color=color, linestyle='-')\n",
    "\n",
    "# Shading attack intervals\n",
    "for interval in test_attacks_index_intervals:\n",
    "    start_idx = interval[\"start\"]\n",
    "    end_idx = interval[\"end\"]\n",
    "\n",
    "    # Adjust the indices to account for the window size\n",
    "    if start_idx >= window_size and end_idx >= window_size:\n",
    "        adjusted_start_idx = start_idx - window_size\n",
    "        adjusted_end_idx = end_idx - window_size\n",
    "        plt.axvspan(hourly_datetime_list[adjusted_start_idx], hourly_datetime_list[adjusted_end_idx], color='red', alpha=0.3)\n",
    "    elif start_idx < window_size and end_idx >= window_size:\n",
    "        adjusted_start_idx = 0\n",
    "        adjusted_end_idx = end_idx - window_size\n",
    "        plt.axvspan(hourly_datetime_list[adjusted_start_idx], hourly_datetime_list[adjusted_end_idx], color='red', alpha=0.3)\n",
    "\n",
    "\n",
    "# Add labels, legend, and title\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Date\", fontsize=font_size)\n",
    "plt.ylabel(\"Reconstruction Error\", fontsize=font_size)\n",
    "\n",
    "# Tick label size\n",
    "plt.tick_params(axis='x', labelsize=font_size)\n",
    "plt.tick_params(axis='y', labelsize=font_size)\n",
    "\n",
    " # First legend: Colors\n",
    "legend1_handles = [\n",
    "       Line2D([0], [0], color='blue', lw=lw, label='TransAE'),\n",
    "       Line2D([0], [0], color='red', lw=lw, label='ConvRecAE'),\n",
    "       Line2D([0], [0], color='green', lw=lw, label='FCAE'),\n",
    "]\n",
    "legend1 = plt.legend(handles=legend1_handles, loc='upper left', title='Attacked data', fontsize=font_size)\n",
    "# Set the font size of the legend title after creation\n",
    "if legend1.get_title():  # Check if there is a title\n",
    "        legend1.get_title().set_fontsize(font_size) # Use the font_size variable\n",
    "plt.gca().add_artist(legend1)  # Add manually to keep it\n",
    "\n",
    "# Second legend: Styles\n",
    "legend2_handles = [\n",
    "       Line2D([0], [0], color='blue', linestyle='--', lw=lw, label='TransAE'),\n",
    "       Line2D([0], [0], color='red', linestyle='--', lw=lw, label='ConvRecAE'),\n",
    "       Line2D([0], [0], color='green', linestyle='--', lw=lw, label='FCAE'),\n",
    "]\n",
    "legend2 = plt.legend(handles=legend2_handles, loc='upper right', title='Benign data', fontsize=font_size)\n",
    "# Set the font size of the legend title after creation\n",
    "if legend2.get_title():  # Check if there is a title\n",
    "        legend2.get_title().set_fontsize(font_size) # Use the font_size variable\n",
    "\n",
    "plt.title(f\"Reconstruction Error Over Time - test data with realistic attacks (window size={window_size}, filter size={filter_size}, anomaly weight = {0.2})\", fontsize=font_size)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to SOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Housh_and_Ohar\": {\n",
    "        \"num_of_detected\": 7,\n",
    "        \"tp\": 388,\n",
    "        \"fp\": 5,\n",
    "        \"tn\": 1677,\n",
    "        \"fn\": 19,\n",
    "        \"tpr\": 0.953,  #  TPR = TP/(TP+FN) => Recall\n",
    "        \"tnr\": 0.997,  #  TNR = TN/(FP+TN)\n",
    "        \"S\": 0.970,\n",
    "        \"Sttd\": 0.965,\n",
    "        \"Sclf\": 0.975,\n",
    "    },\n",
    "    \"Abokifa_et_al\": {\n",
    "        \"num_of_detected\": 7,\n",
    "        \"tp\": 375,\n",
    "        \"fp\": 69,\n",
    "        \"tn\": 1613,\n",
    "        \"fn\": 32,\n",
    "        \"tpr\": 0.921,\n",
    "        \"tnr\": 0.959,\n",
    "        \"S\": 0.949,\n",
    "        \"Sttd\": 0.958,\n",
    "        \"Sclf\": 0.940,\n",
    "    },\n",
    "    \"Giacomoni_et_al\": {\n",
    "        \"num_of_detected\": 7,\n",
    "        \"tp\": 341,\n",
    "        \"fp\": 5,\n",
    "        \"tn\": 1677,\n",
    "        \"fn\": 66,\n",
    "        \"tpr\": 0.838,\n",
    "        \"tnr\": 0.997,\n",
    "        \"S\": 0.927,\n",
    "        \"Sttd\": 0.936,\n",
    "        \"Sclf\": 0.917,\n",
    "    },\n",
    "    \"Brentan_et_al\": {\n",
    "        \"num_of_detected\": 6,\n",
    "        \"tp\": 362,\n",
    "        \"fp\": 45,\n",
    "        \"tn\": 1637,\n",
    "        \"fn\": 45,\n",
    "        \"tpr\": 0.889,\n",
    "        \"tnr\": 0.973,\n",
    "        \"S\": 0.894,\n",
    "        \"Sttd\": 0.857,\n",
    "        \"Sclf\": 0.931,\n",
    "    },\n",
    "    \"Chandy_et_al\": {\n",
    "        \"num_of_detected\": 7,\n",
    "        \"tp\": 349,\n",
    "        \"fp\": 541,\n",
    "        \"tn\": 1141,\n",
    "        \"fn\": 58,\n",
    "        \"tpr\": 0.857,\n",
    "        \"tnr\": 0.678,\n",
    "        \"S\": 0.802,\n",
    "        \"Sttd\": 0.835,\n",
    "        \"Sclf\": 0.768,\n",
    "    },\n",
    "    \"Pasha_et_al\": {\n",
    "        \"num_of_detected\": 7,\n",
    "        \"tp\": 134,\n",
    "        \"fp\": 14,\n",
    "        \"tn\": 1668,\n",
    "        \"fn\": 273,\n",
    "        \"tpr\": 0.329,\n",
    "        \"tnr\": 0.992,\n",
    "        \"S\": 0.773,\n",
    "        \"Sttd\": 0.885,\n",
    "        \"Sclf\": 0.660,\n",
    "    },\n",
    "    \"Aghashahi_et_al\": {\n",
    "        \"num_of_detected\": 3,\n",
    "        \"tp\": 161,\n",
    "        \"fp\": 195,\n",
    "        \"tn\": 1487,\n",
    "        \"fn\": 246,\n",
    "        \"tpr\": 0.396,\n",
    "        \"tnr\": 0.884,\n",
    "        \"S\": 0.534,\n",
    "        \"Sttd\": 0.429,\n",
    "        \"Sclf\": 0.640,\n",
    "    },\n",
    "    \"Stojanovic_et_al\": {\n",
    "        \"num_of_detected\": 7,\n",
    "        \"tp\": 385,\n",
    "        \"fp\": 48,\n",
    "        \"tn\": 1628,\n",
    "        \"fn\": 22,\n",
    "        \"tpr\": 0.9459,\n",
    "        \"tnr\": 0.9717,\n",
    "        \"S\": 0.9571,\n",
    "        \"Sttd\": 0.9556,\n",
    "        \"Sclf\": 0.9587,\n",
    "    },\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "results_df['total_attacks'] = None\n",
    "results_df['total_clean'] = None\n",
    "results_df['missed_attacks'] = None\n",
    "results_df['wrongly_detected'] = None\n",
    "\n",
    "for index, row in results_df.iterrows():\n",
    "  # Calculate the percentage of missed attack samples (False Negatives)\n",
    "  total_attack_samples = row[\"tp\"] + row[\"fn\"]\n",
    "  missed_attacks = row[\"fn\"]\n",
    "  missed_attack_percentage = (missed_attacks / total_attack_samples) * 100\n",
    "\n",
    "  # Calculate the percentage of wrongly detected samples (False Positives)\n",
    "  total_clean_samples = row[\"fp\"] + row[\"tn\"]\n",
    "  wrongly_detected = row[\"fp\"]\n",
    "  wrongly_detected_percentage = (wrongly_detected / total_clean_samples) * 100\n",
    "\n",
    "  results_df.loc[index, 'total_attacks'] = total_attack_samples\n",
    "  results_df.loc[index, 'total_clean'] = total_clean_samples\n",
    "  results_df.loc[index, 'missed_attacks'] = missed_attack_percentage\n",
    "  results_df.loc[index, 'wrongly_detected'] = wrongly_detected_percentage\n",
    "\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
